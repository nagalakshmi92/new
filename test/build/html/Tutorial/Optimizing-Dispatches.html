

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Optimizing-Dispatches &mdash; ReadTheDocs-Breathe 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> ReadTheDocs-Breathe
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../ROCm.html">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Current_Release_Notes/Current-Release-Notes.html">Current Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Installation_Guide/Installation-Guide.html">ROCm Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Programming_Guides/Programming-Guides.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_GPU_Tunning_Guides/ROCm-GPU-Tunning-Guides.html">ROCm GPU Tuning Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GCN_ISA_Manuals/GCN-ISA-Manuals.html">GCN ISA Manuals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_API_References/ROCm-API-References.html">ROCm API References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Tools/ROCm-Tools.html">ROCm Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Libraries/ROCm_Libraries.html">ROCm Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Compiler_SDK/ROCm-Compiler-SDK.html">ROCm Compiler SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_System_Managment/ROCm-System-Managment.html">ROCm System Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Virtualization_Containers/ROCm-Virtualization-&amp;-Containers.html">ROCm Virtualization &amp; Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Remote_Device_Programming/Remote-Device-Programming.html">Remote Device Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Deep_learning/Deep-learning.html">Deep Learning on ROCm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Other_Solutions/Other-Solutions.html">System Level Debug</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Glossary/ROCm-Glossary.html">ROCm Glossary</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ReadTheDocs-Breathe</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Optimizing-Dispatches</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Tutorial/Optimizing-Dispatches.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="optimizing-dispatches">
<span id="id1"></span><h1>Optimizing-Dispatches<a class="headerlink" href="#optimizing-dispatches" title="Permalink to this headline">¶</a></h1>
<div class="section" id="rocm-with-rapid-harmony-optimizing-hsa-dispatch">
<h2>ROCm with Rapid Harmony : Optimizing HSA Dispatch<a class="headerlink" href="#rocm-with-rapid-harmony-optimizing-hsa-dispatch" title="Permalink to this headline">¶</a></h2>
<p>We <a class="reference external" href="https://rocm.github.io/rocncloc.html">previously</a> looked at how to launch an OpenCL™ kernel using the HSA runtime. That example showed the basics of using the HSA Runtime. <a class="reference external" href="https://github.com/ROCm-Developer-Tools/HCC-Example-Application/tree/master/BitonicSort-CL-from-HCC">Here</a> we’ll turn up the tempo a bit by optimizing the launch code - moving some expensive operations into the setup code (rather than on each dispatch), removing host-side synchronization, and optimizing the memory fences to the bare minimum required.  We’ll measure the contributions of the different optimizations and discuss the results.The code is available at the <a class="reference external" href="https://github.com/ROCm-Developer-Tools/HCC-Example-Application/tree/master/BitonicSort-CL-from-HCC">same GitHub repository</a> as before and the optimizations can be enabled with a series of command-line switches.</p>
</div>
<div class="section" id="optimizing">
<h2>Optimizing<a class="headerlink" href="#optimizing" title="Permalink to this headline">¶</a></h2>
<p>Bitonic sort involves running the same kernel several times. For the default array length of 32768, the algorithm launches 120 kernels.  The original OpenCL code and the associated port used in the example synchronize with the host after each of the kernel code.  To improve performance, we can submit all 120 kernels at one time, and only synchronize with the host after the last one completes. To make this change, we will need to restructure the BitonicSort::run call as follows:</p>
<blockquote>
<div><ul class="simple">
<li>Each kernel still needs to wait for the previous kernel to finish executing. The AQL packet in the HSA system architecture defines    a “barrier” bit which provides exactly this synchronization – packets with the barrier bit set will wait for all preceding kernels      in the same queue to complete before beginning their own execution.  Barrier-bit synchronization only works for commands in the        same queue, but will be more efficient than using signals in the cases where it applies.  So we’ll set the barrier bit for all the       kernels to provide the required synchronization between kernels, and therefore will only need to use a completion_signal for the        last kernel in the sequence.  (all other kernels set the completion_signal to 0, which saves an atomic decrement operation when        the command finishes. )  This optimization is marked with p_optPreallocSignal.</li>
<li>In HSA, each kernel submission requires a block of “kernarg” memory to hold the kernel arguments. The  baseline implementation       allocates a single kernarg block and re-uses it for each kernel submission.  In the optimized version, we submit all the kernels        at the same time, but with different kernel arguments, so we must ensure that each kernel has its own kernarg block.  The code          actually performs a single kernarg allocation with enough space to cover all of the inflight kernels.   Additionally, the code          aligns each kernarg block on a 64-byte cache line boundary.  This avoids false-sharing cases where the GPU is reading kernargs for       one command while the host is writing arguments for another kernel, causing the cache line to ping-pong between CPU and GPU            caches.   The kernarg optimizations are marked with p_optPreallocKernarg.</li>
<li>The function bitonicSortGPU_opt contains the optimized loop which submits the batch of 120 kernels to the GPU.  This code is         marked with o_optAvoidHostSync).</li>
<li>Each AQL kernel dispatch packet contains a field that controls the memory fences applied before and after the kernel executes.  In    the baseline implementation, the fences conservatively specify system visibility for both acquire and release fences.  (The            subject of fences and what they control is well beyond the scope of this document but it covered extensively in the HSA System          Architecture Specification Memory Model.  It turns out we can make a more surgical use of these fences in the optimized version:        (code marked with p_optFence)</li>
<li>The first kernel needs a system acquire fence to make sure it gets the data from the host-&gt;device copy.
The last kernel needs a system release fence to make sure it releases the data for the device-&gt;host copy.
All of the intermediate kernels only need to use “agent” level fences.  On the AMD Fiji hardware, agent-scope fences are             significantly faster than system-scope fences since the former flush only the L1 caches while the latter flush both the L1 and the        L2 caches.</li>
</ul>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  // Optimize HSA Fences
  if (p_optFence) {
      aql.header =
          (HSA_PACKET_TYPE_KERNEL_DISPATCH &lt;&lt; HSA_PACKET_HEADER_TYPE) |
           (1 &lt;&lt; HSA_PACKET_HEADER_BARRIER);

      bool setFence=false;

     if (kernelCount == 1) {

          // first packet needs to acquire from system to make sure it gets the host-&gt;device copy:
          aql.header |= (HSA_FENCE_SCOPE_SYSTEM &lt;&lt; HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE);
          aql.header |= (HSA_FENCE_SCOPE_AGENT &lt;&lt; HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE); setFence = true;

      }

      if (kernelCount == numKernels) {
          // last packet needs to release to system to make sure data is visible for device-&gt;host copy:
          aql.header |= (HSA_FENCE_SCOPE_AGENT &lt;&lt; HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE);
          aql.header |= (HSA_FENCE_SCOPE_SYSTEM &lt;&lt; HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE);
          setFence = true;
      }

      if (!setFence) {
          // fences at agent scope:
          aql.header |= (HSA_FENCE_SCOPE_AGENT &lt;&lt; HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE);
          aql.header |= (HSA_FENCE_SCOPE_AGENT &lt;&lt; HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE);
      }
  }

* The flag p_optPinHost uses hc::am_alloc with the amPinnedHost flag to allocate pinned host memory.  Pinned host memory              accelerates the data transfer operations since the runtime will identify that the memory is already pinned and thus immediately         start the DMA transactions - this achieves a peak transfer rate of 13-14GB/s.    Unpinned memory is transferred through a               host-side staging buffer and can be transferred at 6-7GB/s.
</pre></div>
</div>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h2>
<p>After making these changes, we see the speedups shown in the chart and table below.</p>
<img alt="../_images/perf-data.png" src="../_images/perf-data.png" />
<p>The timing numbers shown here includes the time to transfer the array to the GPU, run all of the kernels, and transfer back the result.  The numbers do not include time spent initializing the runtime, allocating memory, or performing the result verification.  The times show the time required to sort 32768 integers using 120 kernels.  This is relatively small size to offload to the GPU (only 128K) and as a result the kernels run in 3-4 us, which stresses the HSA runtime features that we want to discuss.</p>
<table border="1" class="docutils">
<colgroup>
<col width="18%" />
<col width="8%" />
<col width="16%" />
<col width="19%" />
<col width="14%" />
<col width="10%" />
<col width="15%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>&#160;</td>
<td>Baseline</td>
<td>+optPreallocSignal</td>
<td>+optPreallocKernarg</td>
<td>+optAvoidHostSync</td>
<td>+optFence</td>
<td>+optPinnedHost</td>
</tr>
<tr class="row-even"><td>RunTime/Iteration (us)</td>
<td>1943</td>
<td>1906</td>
<td>1869</td>
<td>1665</td>
<td>1221</td>
<td>1137</td>
</tr>
<tr class="row-odd"><td>Delta/Iteration(us)</td>
<td>&#160;</td>
<td>-37</td>
<td>-37</td>
<td>-204</td>
<td>-444</td>
<td>-84</td>
</tr>
</tbody>
</table>
<p>The results show that signal allocation and kernarg allocation both take approximately 37us to complete, which makes sense since both operations require a trip into kernel space (ROCK) and perform memory allocation.  Even the baseline operation shares the signal and kernarg allocation for all 120 kernels but the overhead here is still significant.  Kernels can be dispatched in 5-10us each, so optimal programs definitely will want to perform these operations outside of the critical path.  The optimized code path here moves these operations into the setup routine.  Another option is to create a buffer pool of signals and kernargs (this is the approach used by <a class="reference external" href="https://github.com/RadeonOpenCompute/hcc/blob/master/lib/hsa/mcwamp_hsa.cpp#L47">HCC</a>) or to use thread-local-storage (if thread-safety is required).</p>
<p>Avoiding the host synchronization saves 204us, or about 1.7us per kernel.</p>
<p>The system-scope fences are fairly expensive - Fiji has a 2MB L2 cache, and it takes 3-4 us to flush the entire thing.  Additionally, the bitonic kernel default size is only 128K (32K elements * 4 bytes/element)  which can easily fit in the L2 cache.  Each kernel in the sequence then reads from the L2 and writes the data back to it.  By optimizing these fences to use AGENT scope when possible, we are able to save approximately 3.7us per kernel launch.</p>
<p>Finally, using pinned host memory improves the transfer speeds from around 6GB/s to 14GB/s.    In this workload, we see a modest performance improvement (84us) since most of the benchmark is spent running the kernels and synchronizing between them.</p>
<p>Overall the performance improvement from these optimizations is 1.7X faster than the baseline version.</p>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://en.m.wikipedia.org/wiki/Bitonic_sorter">Wikipedia</a> has a nice description of the Bitonic sort algorithm, including pictures. Eric Bainville wrote a nice explanation <a class="reference external" href="http://www.bealto.com/gpu-sorting_intro.html">here</a> describing how to optimize Bitonic Sort for the GPU.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Thomas Edvalson.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>