

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>HIP FAQ &mdash; ReadTheDocs-Breathe 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> ReadTheDocs-Breathe
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../ROCm.html">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Current_Release_Notes/Current-Release-Notes.html">Current Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Installation_Guide/Installation-Guide.html">ROCm Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Programming-Guides.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_GPU_Tunning_Guides/ROCm-GPU-Tunning-Guides.html">ROCm GPU Tuning Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GCN_ISA_Manuals/GCN-ISA-Manuals.html">GCN ISA Manuals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_API_References/ROCm-API-References.html">ROCm API References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Tools/ROCm-Tools.html">ROCm Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Libraries/ROCm_Libraries.html">ROCm Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Compiler_SDK/ROCm-Compiler-SDK.html">ROCm Compiler SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_System_Managment/ROCm-System-Managment.html">ROCm System Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Virtualization_Containers/ROCm-Virtualization-&amp;-Containers.html">ROCm Virtualization &amp; Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Remote_Device_Programming/Remote-Device-Programming.html">Remote Device Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Deep_learning/Deep-learning.html">Deep Learning on ROCm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Other_Solutions/Other-Solutions.html">System Level Debug</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tutorial/Tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ROCm_Glossary/ROCm-Glossary.html">ROCm Glossary</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ReadTheDocs-Breathe</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>HIP FAQ</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Programming_Guides/HIP-FAQ.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hip-faq">
<span id="id1"></span><h1>HIP FAQ<a class="headerlink" href="#hip-faq" title="Permalink to this headline">Â¶</a></h1>
<p><strong>What APIs and features does HIP support?</strong></p>
<p>HIP provides the following:</p>
<blockquote>
<div><ul class="simple">
<li>Devices (hipSetDevice(), hipGetDeviceProperties(), etc.)</li>
<li>Memory management (hipMalloc(), hipMemcpy(), hipFree(), etc.)</li>
<li>Streams (hipStreamCreate(),hipStreamSynchronize(), hipStreamWaitEvent(), etc.)</li>
<li>Events (hipEventRecord(), hipEventElapsedTime(), etc.)</li>
<li>Kernel launching (hipLaunchKernel is a standard C/C++ function that replaces &lt;&lt;&lt; &gt;&gt;&gt;)</li>
<li>HIP Module API to control when adn how code is loaded.</li>
<li>CUDA-style kernel coordinate functions (threadIdx, blockIdx, blockDim, gridDim)</li>
<li>Cross-lane instructions including shfl, ballot, any, all</li>
<li>Most device-side math built-ins</li>
<li>Error reporting (hipGetLastError(), hipGetErrorString())</li>
</ul>
</div></blockquote>
<p>The HIP API documentation describes each API and its limitations, if any, compared with the equivalent CUDA API.</p>
<p><strong>What is not supported?</strong>
<strong>Runtime/Driver API features</strong></p>
<p>At a high-level, the following features are not supported:</p>
<blockquote>
<div><ul class="simple">
<li>Textures</li>
<li>Dynamic parallelism (CUDA 5.0)</li>
<li>Managed memory (CUDA 6.5)</li>
<li>Graphics interoperability with OpenGL or Direct3D</li>
<li>CUDA Driver API</li>
<li>CUDA IPC Functions (Under Development)</li>
<li>CUDA array, hipmappedArray and pitched memory</li>
<li>MemcpyToSymbol functions</li>
<li>Queue priority controls</li>
</ul>
</div></blockquote>
<p>See the API Support Table for more detailed information.</p>
<p><strong>Kernel language features</strong></p>
<blockquote>
<div><ul class="simple">
<li>Device-side dynamic memory allocations (malloc, free, new, delete) (CUDA 4.0)</li>
<li>Virtual functions, indirect functions and try/catch (CUDA 4.0)</li>
<li>__prof_trigger</li>
<li>PTX assembly (CUDA 4.0). HCC supports inline GCN assembly.</li>
<li><dl class="first docutils">
<dt>Several kernel features are under development. See the HIP Kernel Language for more information. These include:</dt>
<dd><ul class="first last">
<li>printf</li>
<li>assert</li>
<li>__restrict__</li>
<li>__threadfence*_, __syncthreads*</li>
<li>Unbounded loop unroll</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p><strong>Is HIP a drop-in replacement for CUDA?</strong></p>
<p>No. HIP provides porting tools which do most of the work to convert CUDA code into portable C++ code that uses the HIP APIs. Most developers will port their code from CUDA to HIP and then maintain the HIP version. HIP code provides the same performance as native CUDA code, plus the benefits of running on AMD platforms.</p>
<p><strong>What specific version of CUDA does HIP support?</strong></p>
<p>HIP APIs and features do not map to a specific CUDA version. HIP provides a strong subset of functionality provided in CUDA, and the hipify tools can scan code to identify any unsupported CUDA functions - this is useful for identifying the specific features required by a given application.</p>
<p>However, we can provide a rough summary of the features included in each CUDA SDK and the support level in HIP:</p>
<blockquote>
<div><ul>
<li><dl class="first docutils">
<dt>CUDA 4.0 and earlier :</dt>
<dd><ul class="first last simple">
<li>HIP supports CUDA 4.0 except for the limitations described above.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 5.0 :</dt>
<dd><ul class="first simple">
<li>Dynamic Parallelism (not supported)</li>
</ul>
<blockquote class="last">
<div><p>cuIpc functions (under development).</p>
</div></blockquote>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 5.5 :</dt>
<dd><ul class="first last simple">
<li>CUPTI (not directly supported, AMD GPUPerfAPI can be used as an alternative in some cases)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 6.0</dt>
<dd><ul class="first last simple">
<li>Managed memory (under development)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 6.5</dt>
<dd><ul class="first last simple">
<li>__shfl instriniscs (supported)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 7.0</dt>
<dd><ul class="first last simple">
<li>Per-thread-streams (under development)</li>
<li>C++11 (HCC supports all of C++11, all of C++14 and some C++17 features)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 7.5</dt>
<dd><ul class="first last simple">
<li>float16</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>CUDA 8.0</dt>
<dd><ul class="first last simple">
<li>TBD.</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p><strong>What libraries does HIP support?</strong></p>
<p>HIP includes growing support for the 4 key math libraries using hcBlas, hcFft, hcrng and hcsparse. These offer pointer-based memory interfaces (as opposed to opaque buffers) and can be easily interfaced with other HCC applications. Developers should use conditional compilation if portability to nvcc systems is desired - using calls to cu* routines on one path and hc* routines on the other.</p>
<blockquote>
<div><ul class="simple">
<li>hcblas</li>
<li>hcfft</li>
<li>hcsparse</li>
<li>hcrng</li>
</ul>
</div></blockquote>
<p>Additionally, some of the cublas routines are automatically converted to hipblas equivalents by the hipify-clang tool. These APIs use cublas or hcblas depending on the platform, and replace the need to use conditional compilation.</p>
<p><strong>How does HIP compare with OpenCL?</strong></p>
<p>Both AMD and Nvidia support OpenCL 1.2 on their devices, so developers can write portable code. HIP offers several benefits over OpenCL:</p>
<blockquote>
<div><ul class="simple">
<li>Developers can code in C++ as well as mix host and device C++ code in their source files. HIP C++ code can use templates,          lambdas, classes and so on.</li>
<li>The HIP API is less verbose than OpenCL and is familiar to CUDA developers.</li>
<li>Because both CUDA and HIP are C++ languages, porting from CUDA to HIP is significantly easier than porting from CUDA to OpenCL.</li>
<li>HIP uses the best available development tools on each platform: on Nvidia GPUs, HIP code compiles using NVCC and can employ the      nSight profiler and debugger (unlike OpenCL on Nvidia GPUs).</li>
<li>HIP provides pointers and host-side pointer arithmetic.</li>
<li>HIP provides device-level control over memory allocation and placement.</li>
<li>HIP offers an offline compilation model.</li>
</ul>
</div></blockquote>
<p><strong>How does porting CUDA to HIP compare to porting CUDA to OpenCL?</strong></p>
<p>Both HIP and CUDA are dialects of C++, and thus porting between them is relatively straightforward. Both dialects support templates, classes, lambdas, and other C++ constructs. As one example, the hipify tool was originally a Perl script that used simple text conversions from CUDA to HIP. HIP and CUDA provide similar math library calls as well. In summary, the HIP philosophy was to make the HIP language close enough to CUDA that the porting effort is relatively simple. This reduces the potential for error, and also makes it easy to automate the translation. HIPâs goal is to quickly get the ported program running on both platforms with little manual intervention, so that the programmer can focus on performance optimizations.</p>
<p>There have been several tools that have attempted to convert CUDA into OpenCL, such as CU2CL. OpenCL is a C99-based kernel language (rather than C++) and also does not support single-source compilation.
As a result, the OpenCL syntax is different from CUDA, and the porting tools have to perform some heroic transformations to bridge this gap. The tools also struggle with more complex CUDA applications, in particular those that use templates, classes, or other C++ features inside the kernel.</p>
<p><strong>What hardware does HIP support?</strong></p>
<blockquote>
<div><ul class="simple">
<li>For AMD platforms, HIP runs on the same hardware that the HCC âhcâ mode supports. See the ROCm documentation for the list of         supported platforms.</li>
<li>For Nvidia platforms, HIP requires Unified Memory and should run on any device supporting CUDA SDK 6.0 or newer. We have tested       the Nvidia Titan and Tesla K40.</li>
</ul>
</div></blockquote>
<p><strong>Does Hipify automatically convert all source code?</strong></p>
<p>Typically, hipify can automatically convert almost all runtime code, and the coordinate indexing device code ( threadIdx.x -&gt; hipThreadIdx_x ).
Most device code needs no additional conversion, since HIP and CUDA have similar names for math and built-in functions. The hipify-clang tool will automatically modify the kernel signature as needed (automating a step that used to be done manually) Additional porting may be required to deal with architecture feature queries or with CUDA capabilities that HIP doesnât support. In general, developers should always expect to perform some platform-specific tuning and optimization.</p>
<p><strong>What is NVCC?</strong></p>
<p>NVCC is Nvidiaâs compiler driver for compiling âCUDA C++â code into PTX or device code for Nvidia GPUs. Itâs a closed-source binary compiler that is provided by the CUDA SDK.</p>
<p><strong>What is HCC?</strong></p>
<p>HCC is AMDâs compiler driver which compiles âheterogeneous C++â code into HSAIL or GCN device code for AMD GPUs. Itâs an open-source compiler based on recent versions of CLANG/LLVM.</p>
<p><strong>Why use HIP rather than supporting CUDA directly?</strong></p>
<p>While HIP is a strong subset of the CUDA, it is a subset. The HIP layer allows that subset to be clearly defined and documented. Developers who code to the HIP API can be assured their code will remain portable across Nvidia and AMD platforms.
In addition, HIP defines portable mechanisms to query architectural features, and supports a larger 64-bit wavesize which expands the return type for cross-lane functions like ballot and shuffle from 32-bit ints to 64-bit ints.</p>
<p><strong>Can I develop HIP code on an Nvidia CUDA platform?</strong></p>
<p>Yes. HIPâs CUDA path only exposes the APIs and functionality that work on both NVCC and HCC back-ends. âExtraâ APIs, parameters, and features which exist in CUDA but not in HCC will typically result in compile- or runtime errors. Developers need to use the HIP API for most accelerator code, and bracket any CUDA-specific code with preprocessor conditionals. Developers concerned about portability should of course run on both platforms, and should expect to tune for performance. In some cases CUDA has a richer set of modes for some APIs, and some C++ capabilities such as virtual functions - see the HIP &#64;API documentation for more details.</p>
<p><strong>Can I develop HIP code on an AMD HCC platform?</strong></p>
<p>Yes. HIPâs HCC path only exposes the APIs and functions that work on both NVCC and HCC back ends. âExtraâ APIs, parameters and features that appear in HCC but not CUDA will typically cause compile- or runtime errors. Developers must use the HIP API for most accelerator code and bracket any HCC-specific code with preprocessor conditionals. Those concerned about portability should, of course, test their code on both platforms and should tune it for performance. Typically, HCC supports a more modern set of C++11/C++14/C++17 features, so HIP developers who want portability should be careful when using advanced C++ features on the hc path.</p>
<p><strong>Can a HIP binary run on both AMD and Nvidia platforms?</strong></p>
<p>HIP is a source-portable language that can be compiled to run on either the HCC or NVCC platform. HIP tools donât create a âfat binaryâ that can run on either platform, however.</p>
<p><strong>Whatâs the difference between HIP and hc?</strong></p>
<p>HIP is a portable C++ language that supports a strong subset of the CUDA runtime APIs and device-kernel language. Itâs designed to simplify CUDA conversion to portable C++. HIP provides a C-compatible runtime API, C-compatible kernel-launch mechanism, C++ kernel language and pointer-based memory management.</p>
<p>A C++ dialect, hc is supported by the AMD HCC compiler. It provides C++ run time, C++ kernel-launch APIs (parallel_for_each), C++ kernel language, and several memory-management options, including pointers, arrays and array_view (with implicit data synchronization). Itâs intended to be a leading indicator of the ISO C++ standard.</p>
<p><strong>On HCC, can I link HIP code with host code compiled with another compiler such as gcc, icc, or clang ?</strong></p>
<p>Yes. HIP/HCC generates the object code which conforms to the GCC ABI, and also links with libstdc++. This means you can compile host code with the compiler of your choice and link the generated object code with GPU code compiled with HIP. Larger projects often contain a mixture of accelerator code (initially written in CUDA with nvcc) and host code (compiled with gcc, icc, or clang). These projects can convert the accelerator code to HIP, compile that code with hipcc, and link with object code from their preferred compiler.</p>
<p><strong>HIP detected my platform (hcc vs nvcc) incorrectly - what should I do?</strong></p>
<p>HIP will set the platform to HCC if it sees that the AMD graphics driver is installed and has detected an AMD GPU. Sometimes this isnât what you want - you can force HIP to recognize the platform by setting HIP_PLATFORM to hcc (or nvcc)</p>
<p>export HIP_PLATFORM=hcc</p>
<p>One symptom of this problem is the message âerror: âunknown errorâ(11) at square.hipref.cpp:56â. This can occur if you have a CUDA installation on an AMD platform, and HIP incorrectly detects the platform as nvcc. HIP may be able to compile the application using the nvcc tool-chain, but will generate this error at runtime since the platform does not have a CUDA device. The fix is to set HIP_PLATFORM=hcc and rebuild.</p>
<p>If you see issues related to incorrect platform detection, please file an issue with the GitHub issue tracker so we can improve HIPâs platform detection logic.</p>
<p><strong>Can I install both CUDA SDK and HCC on same machine?</strong></p>
<p>Yes. You can use HIP_PLATFORM to choose which path hipcc targets. This configuration can be useful when using HIP to develop an application which is portable to both AMD and NVIDIA.</p>
<p><strong>On CUDA, can I mix CUDA code with HIP code?</strong></p>
<p>Yes. Most HIP data structures (hipStream_t, hipEvent_t) are typedefs to CUDA equivalents and can be intermixed. Both CUDA and HIP use integer device ids. One notable exception is that hipError_t is a new type, and cannot be used where a cudaError_t is expected. In these cases, refactor the code to remove the expectation. Alternatively, hip_runtime_api.h defines functions which convert between the error code spaces:</p>
<p>hipErrorToCudaError hipCUDAErrorTohipError hipCUResultTohipError</p>
<p>If platform portability is important, use #ifdef HIP_PLATFORM_NVCC to guard the CUDA-specific code.</p>
<p><strong>On HCC, can I use HC functionality with HIP?</strong></p>
<p>Yes.
The code can include hc.hpp and use HC functions inside the kernel. A typical use-case is to use AMD-specific hardware features such as the permute, swizzle, or DPP operations. The â-stdlib=libc++â must be passed to hipcc in order to compile hc.hpp. See the âbit_extractâ sample for an example.</p>
<p>Also these functions can be used to extract HCC accelerator and accelerator_view structures from the HIP deviceId and hipStream_t: hipHccGetAccelerator(int deviceId, hc::accelerator <a href="#id2"><span class="problematic" id="id3">*</span></a>acc); hipError_t hipHccGetAcceleratorView(hipStream_t stream, hc::accelerator_view <a href="#id4"><span class="problematic" id="id5">**</span></a>av);</p>
<p>If platform portability is important, use #ifdef HIP_PLATFORM_HIPCC to guard the HCC-specific code.</p>
<p><strong>How do I trace HIP application flow?</strong></p>
<p>See the HIP Profiling Guide for more information.</p>
<p><strong>What if HIP generates error of âsymbol multiply defined!â only on AMD machine?</strong></p>
<p>Unlike CUDA, in HCC, for functions defined in the header files, the keyword of âforceinlineâ does not imply âstaticâ. Thus, if failed to define âstaticâ keyword, you might see a lot of âsymbol multiply defined!â errors at compilation. The workaround is to explicitly add the keyword of âstaticâ before any functions that were defined as âforceinlineâ.</p>
<p><strong>How do I disable HIP Generic Grid Launch option?</strong></p>
<p>Generic Grid Launch(GGL) is currently the default method for hip kernel launch. To disable it and use the legacy grid launch method, please either change the default value of GENERIC_GRID_LAUNCH to 0 in the following to header files and rebuild HIP: $HIP/include/hip/hcc_detail/hip_runtime_api.h $HIP/include/hip/hcc_detail/host_defines.h Or pass â-DGENERIC_GRID_LAUNCH=0â to hipcc at application compilation time.</p>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Thomas Edvalson.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>